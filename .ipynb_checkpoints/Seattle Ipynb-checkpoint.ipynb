{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllSeattleData  = pd.read_csv('seattle_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_column', None)\n",
    "print(AllSeattleData.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(AllSeattleData.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnIndexToRemove = [0,1,2,4,5,11,17, 14, 15, 16]\n",
    "SeattleData  = AllSeattleData.drop(columns=AllSeattleData.iloc[:,columnIndexToRemove].columns)\n",
    "print(\"Removed DataFrame\")\n",
    "print(AllSeattleData.iloc[:,[*columnIndexToRemove]].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "EncodedSeattleData = SeattleData\n",
    "EncodedSeattleData.loc[:, ['room_type']] = EncodedSeattleData.loc[:, ['room_type']].apply(le.fit_transform)\n",
    "encoded = to_categorical(SeattleData['room_type'])\n",
    "newLabels = [\"room_type{}\".format( x ) for x in range(0, len(encoded[0]))]\n",
    "dfToAdd = pd.DataFrame(encoded,columns=newLabels)\n",
    "EncodedSeattleData = pd.concat([EncodedSeattleData, dfToAdd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SeattleData.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncodedSeattleData.drop(columns='room_type', inplace=True)\n",
    "\n",
    "for allColumns in EncodedSeattleData.columns:\n",
    "    EncodedSeattleData[allColumns].fillna((EncodedSeattleData[allColumns].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EncodedSeattleData.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(EncodedSeattleData)\n",
    "# move the column to head of list using index, pop and insert\n",
    "cols.insert(10, cols.pop(cols.index('price')))\n",
    "EncodedSeattleData = EncodedSeattleData.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(EncodedSeattleData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.distplot(SeattleData['price'],rug=True, hist=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Freq Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(SeattleData['room_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myInts = set(SeattleData.columns)\n",
    "myInts.remove('room_type')\n",
    "print(myInts)\n",
    "for variable in myInts:\n",
    "    sns.jointplot(x=SeattleData[variable],y=SeattleData['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "corr = EncodedSeattleData.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <125 is 75% of the data.  This was found in EncodedSeattleData.describe() \n",
    "print(EncodedSeattleData[EncodedSeattleData['price'] >=125].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net, forward Selection model optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential, optimizers, callbacks\n",
    "from keras import losses\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import math\n",
    "scalaFSelect  = ['overall_satisfaction', 'accommodates', 'bedrooms', 'bathrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel(modelName,nfeat,act_func='tanh',optimzer=optimizers.adam(lr=0.1)):\n",
    "    model = Sequential()\n",
    "\n",
    "    if modelName == 'perceptron':\n",
    "        model.add(Dense(8,input_dim=nfeat,activation=act_func, use_bias=True))\n",
    "        model.add(Dense(1))  #1st Hidden Layer - 3 neuron\n",
    "\n",
    "    if modelName == 'neuralnet_3L':\n",
    "        model.add(Dense(5,input_dim=nfeat,activation=act_func, use_bias=True))               #1st Hidden Layer\n",
    "        model.add(Dense(3,activation=act_func))\n",
    "        model.add(Dense(1))                               #Output Layer\n",
    "    if modelName == 'neuralnet_4L':\n",
    "        model.add(Dense(8,input_dim=nfeat,activation=act_func, use_bias=True))               #1st Hidden Layer\n",
    "        model.add(Dense(5,activation=act_func))\n",
    "        model.add(Dense(2,activation=act_func))   #2nd Hidden Layer\n",
    "        model.add(Dense(1, activation=keras.activations.linear))                               #Output Layer             #Output Layer\n",
    "    model.compile(loss=losses.mean_squared_error, optimizer=optimzer)\n",
    "\n",
    "    return model\n",
    "def adj_r2(rSquare, numIndependentVar, numSamples):\n",
    "    return 1-(1-rSquare)*(numSamples -1)/ (numSamples - numIndependentVar - 1)\n",
    "\n",
    "def graphAttsVRVals(rsq, rCv, rbar, numParams, columnName):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(numParams, rsq, label=\"R^2\")\n",
    "    plt.plot( numParams, rCv, label=\"rCv\")\n",
    "    plt.plot(numParams, rbar,  label=\"rAdj\")\n",
    "    plt.xlabel(\"Number params\")\n",
    "    plt.ylabel(\"RVals\")\n",
    "    plt.title(\"RVals for Y={}\".format(columnName))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardSelect( XIndices, colsToUse, xVals, yVals, modelParams, previousRBase):\n",
    "\n",
    "    # param:  XIndices is an array of all incices of the X attributes\n",
    "    # param: colsTouse is ab array of selected columns that the model should use for the base.\n",
    "    # param: modelToUse is the model to predict with.  it should be passed with the object instantiated\n",
    "    initList = XIndices\n",
    "    featuresToUse = colsToUse\n",
    "    # find what index we need to test.  e.i what is not already in the model\n",
    "    featuresToTest = list(set(initList) - set(featuresToUse))\n",
    "\n",
    "    # analyzer will the index of attribute that was tested, and the new r-value the model created with the added attribute\n",
    "    analyzer = pd.Series(index=featuresToTest)\n",
    "\n",
    "    # Get all the columns we need\n",
    "    xInput = xVals.loc[:,[*featuresToUse]]\n",
    "    # have to build\n",
    "    #myBaseModel = buildModel(modelParams['model'], len(xInput.columns), modelParams['activation'], modelParams['optimizer'])\n",
    "    # yVals = yVals.tolist()\n",
    "    #myBaseModel.fit(x=xInput, y=yVals, epochs=modelParams['epochs'], verbose=1)\n",
    "\n",
    "    myBaseRSquare = previousRBase\n",
    "    print(xInput)\n",
    "    print(yVals)\n",
    "    for newColumn in featuresToTest:\n",
    "        # add the feature we want to test to the base X attribtues  we are already using\n",
    "        combinedX = featuresToUse + [newColumn]\n",
    "        # create model with the indices we want to experiment with.\n",
    "\n",
    "        myModel = buildModel(modelParams['model'], len(combinedX), modelParams['activation'], modelParams['optimizer'])\n",
    "        myModel.fit(xVals.iloc[:,[*combinedX]], yVals, epochs=modelParams['epochs'], verbose=1) #modelToUse.fit(xVals.iloc[:,[*combinedX]], yVals)\n",
    "        # add rsquare valeus at location of the index we are experimenting with.\n",
    "\n",
    "        analyzer.loc[newColumn] = r2_score(yVals,myModel.predict(xVals.loc[:,[*combinedX]])) # this gets rsquare value.\n",
    "        print(analyzer)\n",
    "    #if there is a max value in anaylzer.  Let us add that index to the list if the rsquare is better than the current models.\n",
    "    if (analyzer.max()):\n",
    "        if (analyzer.max() > myBaseRSquare):\n",
    "            # index of what column to add that gave best r-value, the actual r-value, rsquar-bar value, and rcv value\n",
    "            return analyzer.idxmax(), analyzer.max()\n",
    "    # else no added features is better than base model\n",
    "    return -1, None\n",
    "\n",
    "def forwardSelectAll(xAtts, yAtts, modelParams):\n",
    "    xIndices = list( (range(0,len(xAtts.columns))))\n",
    "    rSqVals = [-999] # R^2, R^2 Bar, R^2 cv\n",
    "    rCvVals = [0]\n",
    "    rBarVals = [0]\n",
    "    cols = [0] # Question?:  does this value represent the 1's column.\n",
    "    # going to iterate through each value in xIndexArray and pass to forwardSelectMethod to determine rVals\n",
    "    numFeatures = [1]\n",
    "    for i in range(0, len(xAtts.columns)):\n",
    "        myY = yAtts\n",
    "        next_jIdx, next_j = forwardSelect(xIndices, cols, xAtts, myY, modelParams, rSqVals[-1])\n",
    "        if(next_jIdx ==-1):\n",
    "            break # means we found all columns that are significant.\n",
    "        cols.append(next_jIdx)\n",
    "        numFeatures.append(numFeatures[-1]+1)\n",
    "        rSqVals.append(next_j)# calcualte rsquare, rsquarebar, and rcv here.\n",
    "\n",
    "        ## KFOLD R Value\n",
    "        kfold = KFold(n_splits=5, shuffle=True)\n",
    "        cvScoreArray = []\n",
    "        for train, test in kfold.split(xAtts.iloc[:,[*cols]], yAtts):\n",
    "            model = buildModel(modelParams['model'], numFeatures[-1], modelParams['activation'], modelParams['optimizer'])\n",
    "            model.fit(xAtts.iloc[train, [*cols]], yAtts.iloc[train], verbose=0, epochs=modelParams['epochs'])\n",
    "            cvScoreArray.append(r2_score(yAtts.iloc[test], model.predict(xAtts.iloc[test,[*cols]])))\n",
    "        rCvVals.append(sum(cvScoreArray)/len(cvScoreArray))\n",
    "        rBarVals.append(adj_r2(next_j, numFeatures[-1], len(yAtts)))\n",
    "    return cols, numFeatures, rSqVals, rCvVals, rBarVals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NNXL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Select.  Careful of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myOptimizer = optimizers.SGD(learning_rate=.05)\n",
    "\n",
    "myNNXLModelParams = {'model':'neuralnet_4L', 'optimizer':myOptimizer, 'activation': 'sigmoid', 'epochs':200, 'lr':.05}\n",
    "\n",
    "\n",
    "myNNXLData = EncodedSeattleData.copy()\n",
    "myNNXLData.columns = list(range(0, len(myNNXLData.columns)))\n",
    "X= myNNXLData.iloc[:,:-1]\n",
    "y= myNNXLData.iloc[:,-1]\n",
    "X = pd.DataFrame(preprocessing.scale(X))\n",
    "y = pd.DataFrame(preprocessing.scale(y.to_numpy().reshape(-1,1)))\n",
    "\n",
    "\n",
    "myCOls, myNumFeat, rVals, rCV, Radj = forwardSelectAll(X, y, myNNXLModelParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphing\n",
    "rVals.pop(0)\n",
    "rVals.insert(0,0)\n",
    "print(rVals)\n",
    "print(Radj)\n",
    "print(rCV)\n",
    "graphAttsVRVals(rVals, rCV, Radj, myNumFeat, 'price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myX = X.iloc[:, [*myCOls]]\n",
    "print(myX)\n",
    "myModel = buildModel(myNNXLModelParams['model'], len(myX.columns), myNNXLModelParams['activation'], optimzer=myNNXLModelParams['optimizer'] )\n",
    "myModel.fit(x=myX, y=y, epochs=200, verbose=0)\n",
    "_, ax = plt.subplots()\n",
    "ax.scatter(x= range(0, len(myX)), y=y, c='blue', label='actual')\n",
    "ax.scatter(x= range(0, len(myX)), y=myModel.predict(myX),c='red', label='predicted' )\n",
    "plt.legend()\n",
    "#plt.plot(myX, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myModel.predict(myX))\n",
    "print(r2_score(y, myModel.predict(myX)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features that were selected:\")\n",
    "print(EncodedSeattleData.columns[[*myCOls]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
